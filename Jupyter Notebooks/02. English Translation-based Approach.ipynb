{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pickle\n",
    "import stanza\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 4.60MB/s]\n",
      "2021-10-14 14:54:39 INFO: Downloading default packages for language: hy (Armenian)...\n",
      "2021-10-14 14:54:42 INFO: File exists: C:\\Users\\Nigol\\stanza_resources\\hy\\default.zip.\n",
      "2021-10-14 14:54:47 INFO: Finished downloading models and saved to C:\\Users\\Nigol\\stanza_resources.\n",
      "2021-10-14 14:54:47 INFO: Loading these models for language: hy (Armenian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | armtdp  |\n",
      "| mwt       | armtdp  |\n",
      "| pos       | armtdp  |\n",
      "| lemma     | armtdp  |\n",
      "| depparse  | armtdp  |\n",
      "=======================\n",
      "\n",
      "2021-10-14 14:54:47 INFO: Use device: cpu\n",
      "2021-10-14 14:54:47 INFO: Loading: tokenize\n",
      "2021-10-14 14:54:48 INFO: Loading: mwt\n",
      "2021-10-14 14:54:48 INFO: Loading: pos\n",
      "2021-10-14 14:54:48 INFO: Loading: lemma\n",
      "2021-10-14 14:54:48 INFO: Loading: depparse\n",
      "2021-10-14 14:54:49 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "#download stanza and load Armenian treebank\n",
    "stanza.download('hy')\n",
    "nlp = stanza.Pipeline('hy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = pd.read_csv('English.txt', sep = '\\n', header = None, encoding = 'utf-8')\n",
    "armenian = pd.read_csv('Armenian.txt', sep = '\\n', header = None, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "armenian = armenian[0]\n",
    "english = english[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9631\n"
     ]
    }
   ],
   "source": [
    "print(len(armenian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "\n",
    "for i in range(len(armenian)):\n",
    "    g = nlp(armenian[i]).to_dict()\n",
    "    if len(g) != 0:\n",
    "        p = nlp(armenian[i]).to_dict()[0][0]['upos']\n",
    "        pos.append(p)\n",
    "    else:\n",
    "        pos.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add POS tag\n",
    "POS = []\n",
    "for i in range(len(pos)):\n",
    "    if pos[i] == 'ADJ':\n",
    "        POS.append('a')\n",
    "    elif pos[i] == 'ADV':\n",
    "        POS.append('r')\n",
    "    elif pos[i] == 'NOUN':\n",
    "        POS.append('n')\n",
    "    elif pos[i] == 'VERB':\n",
    "        POS.append('v')\n",
    "    else:\n",
    "        POS.append('n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Armenian</th>\n",
       "      <th>English</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ա</td>\n",
       "      <td>the first letter of the Armenian alphabet</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ագահ</td>\n",
       "      <td>greedy,glutton</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ագահություն</td>\n",
       "      <td>greed,greediness,glutton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ագարիկոն</td>\n",
       "      <td>brown mushroom</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ագռավ</td>\n",
       "      <td>crow,raven,spades</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Armenian                                    English POS\n",
       "0            ա  the first letter of the Armenian alphabet   a\n",
       "1         ագահ                             greedy,glutton   a\n",
       "2  ագահություն                   greed,greediness,glutton   n\n",
       "3     ագարիկոն                             brown mushroom   n\n",
       "4        ագռավ                          crow,raven,spades   n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the dataframe and print it\n",
    "columns = ['Armenian', 'English', 'POS']\n",
    "translation = pd.DataFrame(columns = columns)\n",
    "translation['Armenian'] = armenian\n",
    "translation['English'] = english\n",
    "translation['POS'] = POS\n",
    "translation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9631"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>PosScore</th>\n",
       "      <th>NegScore</th>\n",
       "      <th>SynsetTerms</th>\n",
       "      <th>Gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>00001740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>able#1</td>\n",
       "      <td>(usually followed by `to') having the necessar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>00002098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>unable#1</td>\n",
       "      <td>(usually followed by `to') not having the nece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>00002312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>dorsal#2 abaxial#1</td>\n",
       "      <td>facing away from the axis of an organ or organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>00002527</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ventral#2 adaxial#1</td>\n",
       "      <td>nearest to or facing toward the axis of an org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>00002730</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acroscopic#1</td>\n",
       "      <td>facing or on the side toward the apex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  POS        ID  PosScore  NegScore          SynsetTerms  \\\n",
       "0   a  00001740     0.125      0.00               able#1   \n",
       "1   a  00002098     0.000      0.75             unable#1   \n",
       "2   a  00002312     0.000      0.00   dorsal#2 abaxial#1   \n",
       "3   a  00002527     0.000      0.00  ventral#2 adaxial#1   \n",
       "4   a  00002730     0.000      0.00         acroscopic#1   \n",
       "\n",
       "                                               Gloss  \n",
       "0  (usually followed by `to') having the necessar...  \n",
       "1  (usually followed by `to') not having the nece...  \n",
       "2  facing away from the axis of an organ or organ...  \n",
       "3  nearest to or facing toward the axis of an org...  \n",
       "4              facing or on the side toward the apex  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read SentiWordNet\n",
    "swn = pd.read_csv('SentiWordNet_3.0.0.txt', sep = '\\t', encoding = 'utf8', dtype = {'ID':str})\n",
    "swn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-ead87a681183>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  swn['SynsetTerms'][i] = s[:-1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>PosScore</th>\n",
       "      <th>NegScore</th>\n",
       "      <th>SynsetTerms</th>\n",
       "      <th>Gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>00001740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>able</td>\n",
       "      <td>(usually followed by `to') having the necessar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>00002098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>unable</td>\n",
       "      <td>(usually followed by `to') not having the nece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>00002312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>dorsal abaxial</td>\n",
       "      <td>facing away from the axis of an organ or organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>00002527</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ventral adaxial</td>\n",
       "      <td>nearest to or facing toward the axis of an org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>00002730</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acroscopic</td>\n",
       "      <td>facing or on the side toward the apex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  POS        ID  PosScore  NegScore      SynsetTerms  \\\n",
       "0   a  00001740     0.125      0.00             able   \n",
       "1   a  00002098     0.000      0.75           unable   \n",
       "2   a  00002312     0.000      0.00   dorsal abaxial   \n",
       "3   a  00002527     0.000      0.00  ventral adaxial   \n",
       "4   a  00002730     0.000      0.00       acroscopic   \n",
       "\n",
       "                                               Gloss  \n",
       "0  (usually followed by `to') having the necessar...  \n",
       "1  (usually followed by `to') not having the nece...  \n",
       "2  facing away from the axis of an organ or organ...  \n",
       "3  nearest to or facing toward the axis of an org...  \n",
       "4              facing or on the side toward the apex  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(swn)):\n",
    "    terms = swn['SynsetTerms'][i].split()\n",
    "    s = ''\n",
    "    for j in range(len(terms)):\n",
    "        s = s + terms[j][:-2] + ' '\n",
    "    swn['SynsetTerms'][i] = s[:-1]\n",
    "\n",
    "swn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>HWN_Offset</th>\n",
       "      <th>SWN_Offset</th>\n",
       "      <th>Armenian</th>\n",
       "      <th>English</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Objective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [POS, HWN_Offset, SWN_Offset, Armenian, English, Positive, Negative, Objective]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the necessary columns\n",
    "columns = ['POS', 'HWN_Offset', 'SWN_Offset', 'Armenian', 'English', 'Positive', 'Negative', 'Objective']\n",
    "lexicon = pd.DataFrame(columns = columns)\n",
    "lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_scores(index):\n",
    "    pos = swn['PosScore'][index]\n",
    "    neg = swn['NegScore'][index]\n",
    "    num = swn['ID'][index]\n",
    "    return [np.array([pos, neg]), num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 ա\n",
       "1              ագահ\n",
       "2       ագահություն\n",
       "3          ագարիկոն\n",
       "4             ագռավ\n",
       "           ...     \n",
       "9626         ֆիկտիվ\n",
       "9627        Ֆրանսիա\n",
       "9628      ֆրանսուհի\n",
       "9629     ֆրանսիական\n",
       "9630      ֆրանսիացի\n",
       "Name: 0, Length: 9631, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "armenian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>HWN_Offset</th>\n",
       "      <th>SWN_Offset</th>\n",
       "      <th>Armenian</th>\n",
       "      <th>English</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Objective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ա</td>\n",
       "      <td>the first letter of the Armenian alphabet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00011160</td>\n",
       "      <td>ագահ</td>\n",
       "      <td>greedy,glutton</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04945530</td>\n",
       "      <td>ագահություն</td>\n",
       "      <td>greed,greediness,glutton</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ագարիկոն</td>\n",
       "      <td>brown mushroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01579028</td>\n",
       "      <td>ագռավ</td>\n",
       "      <td>crow,raven,spades</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  POS  HWN_Offset SWN_Offset     Armenian  \\\n",
       "0   a         NaN        NaN            ա   \n",
       "1   a         NaN   00011160         ագահ   \n",
       "2   n         NaN   04945530  ագահություն   \n",
       "3   n         NaN        NaN     ագարիկոն   \n",
       "4   n         NaN   01579028        ագռավ   \n",
       "\n",
       "                                     English  Positive  Negative  Objective  \n",
       "0  the first letter of the Armenian alphabet       NaN       NaN        NaN  \n",
       "1                             greedy,glutton       0.0     0.000      1.000  \n",
       "2                   greed,greediness,glutton       0.0     0.375      0.625  \n",
       "3                             brown mushroom       NaN       NaN        NaN  \n",
       "4                          crow,raven,spades       0.0     0.125      0.875  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = []\n",
    "for i in range(len(translation)):\n",
    "    if translation['POS'][i] != 'n/a':\n",
    "        words = str(translation['English'][i]).strip().split(',')\n",
    "        n = len(words)\n",
    "        found = False\n",
    "        for j in range(n):\n",
    "            if words[j] in swn['SynsetTerms'].values:\n",
    "                ind = np.where(swn['SynsetTerms'].values == words[j])[0]\n",
    "                for k in range(len(ind)):\n",
    "                    if swn['POS'][ind[k]] == translation['POS'][i]:\n",
    "                        scores = retrieve_scores(ind[k])\n",
    "                        found = True\n",
    "                        new.append({'POS': translation['POS'][i],'SWN_Offset': scores[1], 'Armenian': translation['Armenian'][i], \n",
    "                                    'English': translation['English'][i], 'Positive': scores[0][0], 'Negative': scores[0][1], \n",
    "                                    'Objective': 1 - np.sum(scores[0])})\n",
    "        p = n\n",
    "        while p > 0 and found == False:\n",
    "            if ' '.join(words[:p]) in swn['Gloss'].values:\n",
    "                ind = np.where(swn['Gloss'].values == ' '.join(words[:p]))[0]\n",
    "                for j in range(len(ind)):\n",
    "                    if swn['POS'][ind[j]] == translation['POS'][i]:\n",
    "                        scores = retrieve_scores(ind[j])\n",
    "                        found = True\n",
    "                        new.append({'POS': translation['POS'][i], 'SWN_Offset': scores[1], 'Armenian': translation['Armenian'][i], \n",
    "                                    'English': translation['English'][i], 'Positive': scores[0][0], 'Negative': scores[0][1], \n",
    "                                    'Objective': 1 - np.sum(scores[0])})\n",
    "            p = p - 1\n",
    "        if found == False:\n",
    "            scores = [[np.nan, np.nan], np.nan]\n",
    "            new.append({'POS': translation['POS'][i], 'SWN_Offset': scores[1], 'Armenian': translation['Armenian'][i], \n",
    "                        'English': translation['English'][i], 'Positive': scores[0][0], 'Negative': scores[0][1], \n",
    "                        'Objective': 1 - np.sum(scores[0])})\n",
    "lexicon = lexicon.append(new, ignore_index = True)\n",
    "lexicon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  ա\n",
       "1               ագահ\n",
       "2        ագահություն\n",
       "3           ագարիկոն\n",
       "4              ագռավ\n",
       "            ...     \n",
       "17071     ֆուտբոլիստ\n",
       "17072         ֆիկտիվ\n",
       "17073      ֆրանսուհի\n",
       "17074     ֆրանսիական\n",
       "17075      ֆրանսիացի\n",
       "Name: Armenian, Length: 17076, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon['Armenian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>HWN_Offset</th>\n",
       "      <th>SWN_Offset</th>\n",
       "      <th>Armenian</th>\n",
       "      <th>English</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Objective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17071</th>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ֆուտբոլիստ</td>\n",
       "      <td>footballer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17072</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ֆիկտիվ</td>\n",
       "      <td>fictitious</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17073</th>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ֆրանսուհի</td>\n",
       "      <td>French</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17074</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ֆրանսիական</td>\n",
       "      <td>French</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17075</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ֆրանսիացի</td>\n",
       "      <td>French</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      POS  HWN_Offset SWN_Offset    Armenian     English  Positive  Negative  \\\n",
       "17071   n         NaN        NaN  ֆուտբոլիստ  footballer       NaN       NaN   \n",
       "17072   a         NaN        NaN      ֆիկտիվ  fictitious       NaN       NaN   \n",
       "17073   n         NaN        NaN   ֆրանսուհի      French       NaN       NaN   \n",
       "17074   a         NaN        NaN  ֆրանսիական     French        NaN       NaN   \n",
       "17075   a         NaN        NaN   ֆրանսիացի      French       NaN       NaN   \n",
       "\n",
       "       Objective  \n",
       "17071        NaN  \n",
       "17072        NaN  \n",
       "17073        NaN  \n",
       "17074        NaN  \n",
       "17075        NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.890138205668773"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the percentage of nan entries in the lexicon dataframe\n",
    "lexicon['Positive'].isna().sum() / len(lexicon) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17076"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the rows with nan scores, reset its index and drop the old one\n",
    "lexicon = lexicon.dropna(subset = ['Positive', 'Negative', 'Objective'])\n",
    "lexicon = lexicon.reset_index()\n",
    "lexicon = lexicon.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe as a pickle file\n",
    "with open('translationScores.pickle', 'wb') as f:\n",
    "    pickle.dump(lexicon, f)\n",
    "    \n",
    "#save the dataframe as a text file (for those interested to read the results)\n",
    "with open('translationScores.txt', 'w', encoding = 'utf-8') as f:\n",
    "    f.write(lexicon.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
