{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the files needed\n",
    "with open('translationScores.pickle', 'rb') as f:\n",
    "    translation_2 = pickle.load(f)\n",
    "\n",
    "with open('hwn.pickle', 'rb') as f:\n",
    "    translation_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12655\n",
      "7363\n"
     ]
    }
   ],
   "source": [
    "#print the length of each dataframe\n",
    "print(len(translation_2))\n",
    "print(len(translation_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4844\n",
      "6055\n"
     ]
    }
   ],
   "source": [
    "#number of unique values in translation and hwn\n",
    "print(len(translation_2['Armenian'].unique()))\n",
    "print(len(translation_1['Armenian'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate translation_1 and 2 dataframes\n",
    "new = pd.concat([translation_1, translation_2], ignore_index = True)\n",
    "new = new.fillna('') #fill any NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HWN_Offset</th>\n",
       "      <th>SWN_Offset</th>\n",
       "      <th>Armenian</th>\n",
       "      <th>English</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Objective</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00014490-a</td>\n",
       "      <td>00014490</td>\n",
       "      <td>միանգամայն բավարար</td>\n",
       "      <td>rich,plentiful,plenteous,copious,ample</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00014490-a</td>\n",
       "      <td>00014490</td>\n",
       "      <td>լիառատ</td>\n",
       "      <td>rich,plentiful,plenteous,copious,ample</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00024996-a</td>\n",
       "      <td>00024996</td>\n",
       "      <td>նոր</td>\n",
       "      <td>new</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.875</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00025470-a</td>\n",
       "      <td>00025470</td>\n",
       "      <td>թթվային</td>\n",
       "      <td>acid</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00029933-a</td>\n",
       "      <td>00029933</td>\n",
       "      <td>ագահ</td>\n",
       "      <td>prehensile,greedy,grasping,grabby,covetous,ava...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20013</th>\n",
       "      <td></td>\n",
       "      <td>02779774</td>\n",
       "      <td>ֆիզիկական</td>\n",
       "      <td>physical</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20014</th>\n",
       "      <td></td>\n",
       "      <td>10428004</td>\n",
       "      <td>ֆիզիկոս</td>\n",
       "      <td>physicist</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20015</th>\n",
       "      <td></td>\n",
       "      <td>10153594</td>\n",
       "      <td>ֆիզկուլտուրնիկ</td>\n",
       "      <td>athlete,gymnast</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20016</th>\n",
       "      <td></td>\n",
       "      <td>03338648</td>\n",
       "      <td>ֆիլմ</td>\n",
       "      <td>film</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20017</th>\n",
       "      <td></td>\n",
       "      <td>03378765</td>\n",
       "      <td>ֆուտբոլ</td>\n",
       "      <td>football</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20018 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HWN_Offset SWN_Offset            Armenian  \\\n",
       "0      00014490-a   00014490  միանգամայն բավարար   \n",
       "1      00014490-a   00014490              լիառատ   \n",
       "2      00024996-a   00024996                 նոր   \n",
       "3      00025470-a   00025470             թթվային   \n",
       "4      00029933-a   00029933                ագահ   \n",
       "...           ...        ...                 ...   \n",
       "20013               02779774           ֆիզիկական   \n",
       "20014               10428004             ֆիզիկոս   \n",
       "20015               10153594      ֆիզկուլտուրնիկ   \n",
       "20016               03338648                ֆիլմ   \n",
       "20017               03378765             ֆուտբոլ   \n",
       "\n",
       "                                                 English  Positive  Negative  \\\n",
       "0                 rich,plentiful,plenteous,copious,ample     0.125     0.000   \n",
       "1                 rich,plentiful,plenteous,copious,ample     0.125     0.000   \n",
       "2                                                    new     0.000     0.125   \n",
       "3                                                   acid     0.000     0.375   \n",
       "4      prehensile,greedy,grasping,grabby,covetous,ava...     0.000     0.000   \n",
       "...                                                  ...       ...       ...   \n",
       "20013                                           physical     0.000     0.000   \n",
       "20014                                          physicist     0.000     0.000   \n",
       "20015                                    athlete,gymnast     0.000     0.000   \n",
       "20016                                               film     0.000     0.000   \n",
       "20017                                           football     0.000     0.000   \n",
       "\n",
       "       Objective POS  \n",
       "0          0.875      \n",
       "1          0.875      \n",
       "2          0.875      \n",
       "3          0.625      \n",
       "4          1.000      \n",
       "...          ...  ..  \n",
       "20013      1.000   a  \n",
       "20014      1.000   n  \n",
       "20015      1.000   n  \n",
       "20016      1.000   n  \n",
       "20017      1.000   n  \n",
       "\n",
       "[20018 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the result\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the necessary columns\n",
    "columns = ['HWN_Offset', 'SWN_Offset', 'Part_of_Speech', 'Armenian', 'English', 'Positive', 'Negative', 'Objective']\n",
    "lexicon = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = new['Armenian'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HWN_Offset</th>\n",
       "      <th>SWN_Offset</th>\n",
       "      <th>Part_of_Speech</th>\n",
       "      <th>Armenian</th>\n",
       "      <th>English</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Objective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[00014490-a]</td>\n",
       "      <td>[00014490]</td>\n",
       "      <td></td>\n",
       "      <td>միանգամայն բավարար</td>\n",
       "      <td>[rich,plentiful,plenteous,copious,ample]</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[00014490-a]</td>\n",
       "      <td>[00014490]</td>\n",
       "      <td></td>\n",
       "      <td>լիառատ</td>\n",
       "      <td>[rich,plentiful,plenteous,copious,ample]</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[00024996-a, 00818008-a, 01640850-a, 01687167-...</td>\n",
       "      <td>[00024996, 00818008, 01640850, 01687167, 00821...</td>\n",
       "      <td></td>\n",
       "      <td>նոր</td>\n",
       "      <td>[new, young,new, novel,new,fresh]</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.78125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[00025470-a]</td>\n",
       "      <td>[00025470]</td>\n",
       "      <td></td>\n",
       "      <td>թթվային</td>\n",
       "      <td>[acid]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.62500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[00029933-a, ]</td>\n",
       "      <td>[00029933, 00011160]</td>\n",
       "      <td></td>\n",
       "      <td>ագահ</td>\n",
       "      <td>[prehensile,greedy,grasping,grabby,covetous,av...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          HWN_Offset  \\\n",
       "0                                       [00014490-a]   \n",
       "1                                       [00014490-a]   \n",
       "2  [00024996-a, 00818008-a, 01640850-a, 01687167-...   \n",
       "3                                       [00025470-a]   \n",
       "4                                     [00029933-a, ]   \n",
       "\n",
       "                                          SWN_Offset Part_of_Speech  \\\n",
       "0                                         [00014490]                  \n",
       "1                                         [00014490]                  \n",
       "2  [00024996, 00818008, 01640850, 01687167, 00821...                  \n",
       "3                                         [00025470]                  \n",
       "4                               [00029933, 00011160]                  \n",
       "\n",
       "             Armenian                                            English  \\\n",
       "0  միանգամայն բավարար           [rich,plentiful,plenteous,copious,ample]   \n",
       "1              լիառատ           [rich,plentiful,plenteous,copious,ample]   \n",
       "2                 նոր                  [new, young,new, novel,new,fresh]   \n",
       "3             թթվային                                             [acid]   \n",
       "4                ագահ  [prehensile,greedy,grasping,grabby,covetous,av...   \n",
       "\n",
       "   Positive  Negative  Objective  \n",
       "0  0.125000  0.000000    0.87500  \n",
       "1  0.125000  0.000000    0.87500  \n",
       "2  0.171875  0.046875    0.78125  \n",
       "3  0.000000  0.375000    0.62500  \n",
       "4  0.000000  0.000000    1.00000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = []\n",
    "for i in range(len(lemmas)):\n",
    "    word = lemmas[i]\n",
    "    ind = np.where(new['Armenian'] == word)[0]\n",
    "    POS = new['POS'][ind[0]]\n",
    "    pos, neg, obj = 0, 0, 0\n",
    "    s_offset = []\n",
    "    h_offset = []\n",
    "    eng = []\n",
    "    for j in range(len(ind)):\n",
    "        pos += new['Positive'][ind[j]]\n",
    "        neg += new['Negative'][ind[j]]\n",
    "        obj += new['Objective'][ind[j]]\n",
    "        s_offset.append(new['SWN_Offset'][ind[j]])\n",
    "        h_offset.append(new['HWN_Offset'][ind[j]])\n",
    "        if new['English'][ind[j]] not in eng:\n",
    "            eng.append(new['English'][ind[j]])\n",
    "    positive = pos / len(ind)\n",
    "    negative = neg / len(ind)\n",
    "    objective = obj / len(ind)\n",
    "    sentiment.append({'HWN_Offset': h_offset, 'SWN_Offset': s_offset, 'Part_of_Speech': POS, 'Armenian': word, 'English': eng, \n",
    "                      'Positive': positive, 'Negative': negative, 'Objective': objective})\n",
    "lexicon = lexicon.append(sentiment, ignore_index = True)\n",
    "lexicon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-d8002536fe55>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lexicon['HWN_Offset'][i] = ','.join(lexicon['HWN_Offset'][i])\n",
      "<ipython-input-10-d8002536fe55>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lexicon['SWN_Offset'][i] = ','.join(lexicon['SWN_Offset'][i])\n",
      "<ipython-input-10-d8002536fe55>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lexicon['English'][i] = ','.join(lexicon['English'][i])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HWN_Offset</th>\n",
       "      <th>SWN_Offset</th>\n",
       "      <th>Part_of_Speech</th>\n",
       "      <th>Armenian</th>\n",
       "      <th>English</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Objective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00014490-a</td>\n",
       "      <td>00014490</td>\n",
       "      <td></td>\n",
       "      <td>միանգամայն բավարար</td>\n",
       "      <td>rich,plentiful,plenteous,copious,ample</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00014490-a</td>\n",
       "      <td>00014490</td>\n",
       "      <td></td>\n",
       "      <td>լիառատ</td>\n",
       "      <td>rich,plentiful,plenteous,copious,ample</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00024996-a,00818008-a,01640850-a,01687167-a,,,,</td>\n",
       "      <td>00024996,00818008,01640850,01687167,00821208,0...</td>\n",
       "      <td></td>\n",
       "      <td>նոր</td>\n",
       "      <td>new,young,new,novel,new,fresh</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.78125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00025470-a</td>\n",
       "      <td>00025470</td>\n",
       "      <td></td>\n",
       "      <td>թթվային</td>\n",
       "      <td>acid</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.62500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00029933-a,</td>\n",
       "      <td>00029933,00011160</td>\n",
       "      <td></td>\n",
       "      <td>ագահ</td>\n",
       "      <td>prehensile,greedy,grasping,grabby,covetous,ava...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        HWN_Offset  \\\n",
       "0                                       00014490-a   \n",
       "1                                       00014490-a   \n",
       "2  00024996-a,00818008-a,01640850-a,01687167-a,,,,   \n",
       "3                                       00025470-a   \n",
       "4                                      00029933-a,   \n",
       "\n",
       "                                          SWN_Offset Part_of_Speech  \\\n",
       "0                                           00014490                  \n",
       "1                                           00014490                  \n",
       "2  00024996,00818008,01640850,01687167,00821208,0...                  \n",
       "3                                           00025470                  \n",
       "4                                  00029933,00011160                  \n",
       "\n",
       "             Armenian                                            English  \\\n",
       "0  միանգամայն բավարար             rich,plentiful,plenteous,copious,ample   \n",
       "1              լիառատ             rich,plentiful,plenteous,copious,ample   \n",
       "2                 նոր                      new,young,new,novel,new,fresh   \n",
       "3             թթվային                                               acid   \n",
       "4                ագահ  prehensile,greedy,grasping,grabby,covetous,ava...   \n",
       "\n",
       "   Positive  Negative  Objective  \n",
       "0  0.125000  0.000000    0.87500  \n",
       "1  0.125000  0.000000    0.87500  \n",
       "2  0.171875  0.046875    0.78125  \n",
       "3  0.000000  0.375000    0.62500  \n",
       "4  0.000000  0.000000    1.00000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(lexicon)):\n",
    "    lexicon['HWN_Offset'][i] = ','.join(lexicon['HWN_Offset'][i])\n",
    "    lexicon['SWN_Offset'][i] = ','.join(lexicon['SWN_Offset'][i])\n",
    "    lexicon['English'][i] = ','.join(lexicon['English'][i])\n",
    "lexicon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9292\n"
     ]
    }
   ],
   "source": [
    "#number of unique in new\n",
    "print(len(lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe as a pickle file\n",
    "with open('sentimentScores_final.pickle', 'wb') as f:\n",
    "    pickle.dump(lexicon, f)\n",
    "    \n",
    "#save the dataframe as a text file (for those interested to read the results)\n",
    "with open('sentimentScores_final.txt', 'w', encoding = 'utf-8') as f:\n",
    "    f.write(lexicon.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
